# Ollama Configuration
OLLAMA_HOST=0.0.0.0
OLLAMA_PORT=11434
OLLAMA_MODELS_DIR=/root/.ollama/models

# Model Configuration
DEFAULT_MODEL=deepseek:latest
SECONDARY_MODEL=llama2:13b-chat-q4_0

# GPU Configuration
CUDA_VISIBLE_DEVICES=0
NVIDIA_VISIBLE_DEVICES=all
